{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4565d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d10b8a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('D:\\\\AI_Diploma\\\\AI_diploma\\\\flask\\\\project\\\\data.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd205fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = []\n",
    "# labels = []\n",
    "# for item in data [\"data\"]:\n",
    "#     for pattern in item[\"patterns\"]:\n",
    "#         text.append(pattern)\n",
    "#         labels.append(item[\"label\"])\n",
    "\n",
    "\n",
    "text = []\n",
    "labels = []\n",
    "\n",
    "for item in data:  \n",
    "    for pattern in item[\"patterns\"]:\n",
    "        text.append(pattern)\n",
    "        labels.append(item[\"tag\"])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0119452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=2000)\n",
    "X = vectorizer.fit_transform(text).toarray()\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c7d2755",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(vectorizer, open('vectorizer.pkl', 'wb'))\n",
    "pickle.dump(le, open('label_encoder.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "993204ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class chatDataset(Dataset):\n",
    "    def __init__ (self,X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1749ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"d:\\AI_Diploma\\AI_diploma\\venv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"d:\\AI_Diploma\\AI_diploma\\venv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"d:\\AI_Diploma\\AI_diploma\\venv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"d:\\AI_Diploma\\AI_diploma\\venv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\aa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\aa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\aa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"d:\\AI_Diploma\\AI_diploma\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"d:\\AI_Diploma\\AI_diploma\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"d:\\AI_Diploma\\AI_diploma\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"d:\\AI_Diploma\\AI_diploma\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"d:\\AI_Diploma\\AI_diploma\\venv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"d:\\AI_Diploma\\AI_diploma\\venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"d:\\AI_Diploma\\AI_diploma\\venv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"d:\\AI_Diploma\\AI_diploma\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"d:\\AI_Diploma\\AI_diploma\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"d:\\AI_Diploma\\AI_diploma\\venv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"d:\\AI_Diploma\\AI_diploma\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"d:\\AI_Diploma\\AI_diploma\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"d:\\AI_Diploma\\AI_diploma\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\aa\\AppData\\Local\\Temp\\ipykernel_1060\\3536633416.py\", line 1, in <module>\n",
      "    dataset = chatDataset(X, y)\n",
      "  File \"C:\\Users\\aa\\AppData\\Local\\Temp\\ipykernel_1060\\1218752669.py\", line 3, in __init__\n",
      "    self.X = torch.tensor(X, dtype=torch.float32)\n",
      "C:\\Users\\aa\\AppData\\Local\\Temp\\ipykernel_1060\\1218752669.py:3: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  self.X = torch.tensor(X, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "dataset = chatDataset(X, y)\n",
    "loader = DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55056173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Model ----- \n",
    "\n",
    "class ChatModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ChatModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95c65a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 127.3689\n",
      "Epoch 2, Loss: 122.9506\n",
      "Epoch 3, Loss: 115.7915\n",
      "Epoch 4, Loss: 107.8384\n",
      "Epoch 5, Loss: 98.3695\n",
      "Epoch 6, Loss: 93.6840\n",
      "Epoch 7, Loss: 86.2258\n",
      "Epoch 8, Loss: 76.7911\n",
      "Epoch 9, Loss: 68.8574\n",
      "Epoch 10, Loss: 61.9363\n",
      "Epoch 11, Loss: 55.0299\n",
      "Epoch 12, Loss: 49.0805\n",
      "Epoch 13, Loss: 43.9291\n",
      "Epoch 14, Loss: 38.4801\n",
      "Epoch 15, Loss: 34.4010\n",
      "Epoch 16, Loss: 31.3779\n",
      "Epoch 17, Loss: 26.0508\n",
      "Epoch 18, Loss: 22.7604\n",
      "Epoch 19, Loss: 20.3766\n",
      "Epoch 20, Loss: 18.3682\n",
      "Epoch 21, Loss: 16.3088\n",
      "Epoch 22, Loss: 15.3466\n",
      "Epoch 23, Loss: 13.8944\n",
      "Epoch 24, Loss: 13.3256\n",
      "Epoch 25, Loss: 11.8691\n",
      "Epoch 26, Loss: 11.3767\n",
      "Epoch 27, Loss: 10.5228\n",
      "Epoch 28, Loss: 9.8391\n",
      "Epoch 29, Loss: 9.5365\n",
      "Epoch 30, Loss: 9.0564\n",
      "✅ Training done and model saved as model.pth\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "input_dim = X.shape[1]\n",
    "hidden_dim = 128\n",
    "output_dim = len(le.classes_)\n",
    "\n",
    "model = ChatModel(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "for epoch in range(30):\n",
    "    total_loss = 0\n",
    "    for X_batch , y_batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()#update weights\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "# ----- Save model -----\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "\n",
    "print(\"✅ Training done and model saved as model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27785533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
